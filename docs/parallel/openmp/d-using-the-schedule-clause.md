---
title: 'D: Schedule 句の使用'
ms.date: 11/04/2016
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 85386c913a6e447ba9e71231be8b951eef504fea
ms.sourcegitcommit: 6052185696adca270bc9bdbec45a626dd89cdcdd
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/31/2018
ms.locfileid: "50627527"
---
# <a name="d-using-the-schedule-clause"></a>D: Schedule 句の使用

並列領域は、少なくとも 1 つのバリアを末尾が、内に別の障壁があります。 各バリアで、チームの他のメンバーは、最後のスレッドが到着するを待つ必要があります。 この待機時間を最小限に抑えるには、すべてのスレッドがほぼ同時にバリアに到達できるように、共有の作業を分散する必要があります。 作業が含まれている場合、共有の一部を**の**構築では、`schedule`句は、この目的に使用できます。

スケジュールの選択、同じオブジェクトを繰り返し参照がある場合に、**の**プレゼンスとキャッシュとメモリにアクセスするかのサイズなど、メモリ システムの特徴で主に決定されるコンストラクト時間は、uniform または nonuniform です。 このような考慮事項がなります。 いくつかのスレッドは比較的少ない作業で、ループの一部を割り当てられている場合でも一貫して同じ一連のループ、配列の要素のセットを参照する各スレッドがあることをお勧めです。 これを使用して行うことができます、**静的**for ループをすべて同じ境界を持つスケジュールします。 次の例で 2 つ目のループ内の下限としてゼロがたとえ使用**k**スケジュールが重要でない場合より自然になります。

```
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

その他の例ではそのメモリものとアクセスは主要な考慮事項と、特に明記しない限り、すべてのスレッドが比較可能なコンピューティング リソースを受信します。 スケジュールの選択のこれらのケースで、**の**コンス トラクターは、最も近い先行間で実行するのには、すべての共有作業によって異なりますバリアと暗黙的なバリアまたは後続のバリアがある場合に最も近い。`nowait`句。 スケジュールの種類ごとに、簡単な例は、そのスケジュールの種類が最適な選択をする可能性がありますする方法を示します。 簡単な説明では、それぞれの例に従います。

**静的**スケジュールが最も簡単な場合は、1 つを含む、並行領域の適切なも**の**同じ量の作業が必要なを構築します。

```
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

**静的**スケジュールの特徴は、プロパティの各スレッドは、約、他のスレッドとのイテレーションの同じ番号を取得して、各スレッドは個別に判断するのに割り当てられるイテレーション。 したがって同期は必要ありません、作業を分散して、各イテレーションが、同じ量の作業が必要なことを前提と、すべてのスレッドは同じ時刻について完了にする必要があります。

チームの`p`のスレッドを使用*ceiling (n/p)* 、整数である*q*、これを満たす*n = p\*q - r*で*0 < = r < p*. 実装の 1 つ、**静的**割り当てることがこの例のスケジュール*q*最初のイテレーション*p-1*スレッド、および*q r*最後のスレッドをイテレーションします。  もう 1 つの許容可能な実装を割り当てることが*q*最初のイテレーション*p r*スレッド、および*q-1* 、残りのイテレーション*r*スレッド。 これは、プログラムが特定の実装の詳細に依存する必要がありますしない理由を示しています。

**動的**スケジュールはの大文字と小文字を適切な**の**作業量がさまざまな、または予測不能で必要とするイテレーションを作成します。

```
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

**動的**スケジュールが待機しないバリアでよりも長くはその最後の反復処理を実行する別のスレッドのプロパティによって特徴付けられます。 これは、イテレーションに割り当てられることを一度に 1 つのスレッド割り当てごとに同期で、利用可能になる必要があります。 最小チャンク サイズを指定することで、同期のオーバーヘッドを削減できます*k*スレッドが割り当てられているように、1 より大きい*k*までよりも少ない、一度に*k*ままにします。 これにより、(1) その最後のチャンクを実行する別のスレッドがより長くバリアでスレッドが待機しない*k*イテレーション。

**動的**スケジュールできる、コンピューティング リソースをさまざまなスレッドが表示される場合に役立ちます。 各イテレーションの作業の量は変化とほぼ同じ結果があります。 同様に、動的なスケジュールにも役立ちます、スレッドが到着する場合、**の**がいくつかでこのような場合のさまざまな時間は、構築、**ガイド付き**スケジュールが望ましいことがあります。

**ガイド付き**スケジュールは、さまざまなタイミングで受信したスレッドをケースに適した、**の**の各反復処理を必要とする同じ量の作業について構築します。 これは、場合に発生、たとえば、**の**コンストラクトの 1 つまたは複数のセクションが付いてまたは**の**構造は`nowait`句。

```
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

ような**動的**、**ガイド付き**最後の反復処理を実行する別のスレッドの所要時間よりも長いまたは最終的なバリアでスレッドが待機しないことを保証をスケジュール*k*場合のチャンク サイズをイテレーション*k*を指定します。 このようなスケジュールでは、間、**ガイド付き**スケジュールのプロパティで特徴は、最小限の同期が必要であります。 チャンク サイズの*k*、一般的な実装が割り当てられます*q = ceiling (n/p)* 最初の使用可能なスレッドのイテレーションの設定*n* 、大きい方の*n-q*と*p\*k*、割り当てられているすべてのイテレーションになるまで繰り返します。

最適なスケジュールの選択がこれらの例については、それが明確でない場合に、**ランタイム**スケジュールは、さまざまなスケジュールとチャンクのサイズを変更して、プログラムを再コンパイルしなくても試すに便利です。 最適なスケジュールがプログラムを適用する入力データに対して (予測可能な方法はいくつか) に依存する場合に便利ですできます。

さまざまなスケジュール間のトレードオフの例を確認するには、8 つのスレッド間で 1000 回の繰り返しの共有を検討してください。 各イテレーションで作業量がインバリアントであると仮定し、時間の単位として使用します。

すべてのスレッドが、同時に開始する場合、**静的**同期なしの 125 単位で実行する構成要素により、スケジュールします。 1 つのスレッドが到着遅延に 100 単位であるとします。 バリアで 100 単位の残りの 7 つのスレッドを待機し、225 に構造体全体の実行に時間が増加します。

ため、両方の**動的**と**ガイド付き**バリアで 1 つ以上の単位のスレッドが待機しないこと、遅延のスレッドが 138 にしか増加コンス トラクターの実行時間が発生し、スケジュールを確認しますこのユニットを使用して、同期からの遅延によって増加可能性があります。 同期の数が 1000 で重要になりますこのような遅延がごくわずかでない場合は、**動的**が唯一の 41 で**ガイド付き**、1 つの既定のチャンク サイズを想定します。 チャンク サイズが 25、**動的**と**ガイド付き**150 の単位と必要な同期を 40 と 20、のみを今すぐ数から遅延それぞれ完了両方。